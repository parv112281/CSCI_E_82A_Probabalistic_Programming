{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "## Graphical Parameters and Model Structure\n",
    "\n",
    "In the previous homework, you performed queries on a graphical model of possible murders and murder weapons. Now, you will estimate model parameters and structure using data.   \n",
    "\n",
    "As a reminder, the joint probability distribution is:\n",
    "\n",
    "$$p(B,C,W,MO,M)$$     \n",
    "\n",
    "where the letters indicate the following variables;   \n",
    "$B = $ butler committed the crime, {not murderer, murderer},   \n",
    "$C = $ cook committed the crime, {not murderer, murderer},    \n",
    "$W = $ choice of weapon, {poison, knife}, conditional on butler and cook,  \n",
    "$MO = $motive for the murder, {no motive, has motive}, conditional on butler and cook,   \n",
    "$M = $ murderer {butler or cook, third party alone}.    \n",
    "\n",
    "We have determined that the joint distribution can be factored:\n",
    "\n",
    "$$p(B,C,W,MO,M) = p(B)\\ p(C)\\ p(W\\ |\\ B, C)\\ p(MO\\ |\\ B,C)\\ p(M\\ |\\ B,C,MO,W)$$  \n",
    "\n",
    "A graph of the model is shown below. \n",
    "\n",
    "<img src=\"MurderDirected.JPG\" alt=\"Drawing\" style=\"width:500px; height:300px\"/>\n",
    "<center> DAG for murder evidence </center>\n",
    "\n",
    "Notice that the skeleton of this graph does not have a tree structure. This fact will limit how well estimation algorithms will work, particularly for graph structure. Keep this fact in mind as you proceed. \n",
    "\n",
    "As a first step execute the code in the below to simulate the 25 cases from the Bayesian directed model you have previously created. Examine the code to see the CPD tables for this simulation. \n",
    "\n",
    "> **Note:** You must change the name of the pickled model file in the `open` statement to match the file name you are using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model loaded correctly: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>W</th>\n",
       "      <th>MO</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    C  B  W  MO  M\n",
       "0   0  1  1   1  2\n",
       "1   0  0  1   0  0\n",
       "2   1  1  0   1  1\n",
       "3   1  1  1   1  2\n",
       "4   0  0  1   0  0\n",
       "5   0  0  1   0  0\n",
       "6   1  0  1   1  1\n",
       "7   0  1  1   1  2\n",
       "8   0  1  1   1  2\n",
       "9   0  1  0   1  2\n",
       "10  1  1  0   1  2\n",
       "11  0  0  1   0  0\n",
       "12  1  1  0   1  2\n",
       "13  0  1  1   1  2\n",
       "14  1  1  0   1  1\n",
       "15  0  1  1   1  2\n",
       "16  0  1  1   1  2\n",
       "17  0  1  1   1  2\n",
       "18  0  0  1   0  0\n",
       "19  0  1  1   1  2\n",
       "20  0  0  1   0  0\n",
       "21  1  0  0   0  1\n",
       "22  1  0  1   1  1\n",
       "23  0  1  0   1  2\n",
       "24  1  0  1   0  1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Simulate the binary tables\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "import pickle\n",
    "\n",
    "## Load the model from a file\n",
    "with open('murder_model.pkl', 'rb') as pkl:\n",
    "    murder_model = pickle.load(pkl)\n",
    "print('The model loaded correctly: {}'.format(murder_model.check_model()))\n",
    "\n",
    "## Simulate values from the DAG\n",
    "def simulate_from_DAG(model, nsamps = 25, set_seed = 234):\n",
    "    nr.seed(set_seed)\n",
    "    simulation = BayesianModelSampling(model)\n",
    "    return(simulation.forward_sample(size = nsamps, return_type='dataframe'))\n",
    "\n",
    "\n",
    "nsamps = 25\n",
    "samples_25 = simulate_from_DAG(murder_model, nsamps = nsamps)\n",
    "samples_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Parameter Estimation\n",
    "\n",
    "With the dataset generated you will now estimate the parameters of the graphical model using both maximum likelihood and Bayesian methods. \n",
    "\n",
    "As a first step execute the code in the cell below to load the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore, K2Score, StructureScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create and execute the code in the cell below to estimate and display the parameters of the CPDs using the **maximum likelihood method** from the simulated graphy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPD of B:\n",
      "+------+-----+\n",
      "| B(0) | 0.4 |\n",
      "+------+-----+\n",
      "| B(1) | 0.6 |\n",
      "+------+-----+\n",
      "CPD of C:\n",
      "+------+------+\n",
      "| C(0) | 0.64 |\n",
      "+------+------+\n",
      "| C(1) | 0.36 |\n",
      "+------+------+\n",
      "CPD of M:\n",
      "+------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+--------------------+-------+-------+\n",
      "| B    | B(0)               | B(0)  | B(0)               | B(0)               | B(0)  | B(0)  | B(0)               | B(0)  | B(1)               | B(1)               | B(1)  | B(1)  | B(1)               | B(1)               | B(1)  | B(1)  |\n",
      "+------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+--------------------+-------+-------+\n",
      "| C    | C(0)               | C(0)  | C(0)               | C(0)               | C(1)  | C(1)  | C(1)               | C(1)  | C(0)               | C(0)               | C(0)  | C(0)  | C(1)               | C(1)               | C(1)  | C(1)  |\n",
      "+------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+--------------------+-------+-------+\n",
      "| MO   | MO(0)              | MO(0) | MO(1)              | MO(1)              | MO(0) | MO(0) | MO(1)              | MO(1) | MO(0)              | MO(0)              | MO(1) | MO(1) | MO(0)              | MO(0)              | MO(1) | MO(1) |\n",
      "+------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+--------------------+-------+-------+\n",
      "| W    | W(0)               | W(1)  | W(0)               | W(1)               | W(0)  | W(1)  | W(0)               | W(1)  | W(0)               | W(1)               | W(0)  | W(1)  | W(0)               | W(1)               | W(0)  | W(1)  |\n",
      "+------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+--------------------+-------+-------+\n",
      "| M(0) | 0.3333333333333333 | 1.0   | 0.3333333333333333 | 0.3333333333333333 | 0.0   | 0.0   | 0.3333333333333333 | 0.0   | 0.3333333333333333 | 0.3333333333333333 | 0.0   | 0.0   | 0.3333333333333333 | 0.3333333333333333 | 0.0   | 0.0   |\n",
      "+------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+--------------------+-------+-------+\n",
      "| M(1) | 0.3333333333333333 | 0.0   | 0.3333333333333333 | 0.3333333333333333 | 1.0   | 1.0   | 0.3333333333333333 | 1.0   | 0.3333333333333333 | 0.3333333333333333 | 0.0   | 0.0   | 0.3333333333333333 | 0.3333333333333333 | 0.5   | 0.0   |\n",
      "+------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+--------------------+-------+-------+\n",
      "| M(2) | 0.3333333333333333 | 0.0   | 0.3333333333333333 | 0.3333333333333333 | 0.0   | 0.0   | 0.3333333333333333 | 0.0   | 0.3333333333333333 | 0.3333333333333333 | 1.0   | 1.0   | 0.3333333333333333 | 0.3333333333333333 | 0.5   | 1.0   |\n",
      "+------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+-------+--------------------+--------------------+-------+-------+--------------------+--------------------+-------+-------+\n",
      "CPD of MO:\n",
      "+-------+------+------+------+------+\n",
      "| B     | B(0) | B(0) | B(1) | B(1) |\n",
      "+-------+------+------+------+------+\n",
      "| C     | C(0) | C(1) | C(0) | C(1) |\n",
      "+-------+------+------+------+------+\n",
      "| MO(0) | 1.0  | 0.5  | 0.0  | 0.0  |\n",
      "+-------+------+------+------+------+\n",
      "| MO(1) | 0.0  | 0.5  | 1.0  | 1.0  |\n",
      "+-------+------+------+------+------+\n",
      "CPD of W:\n",
      "+------+------+------+------+------+\n",
      "| B    | B(0) | B(0) | B(1) | B(1) |\n",
      "+------+------+------+------+------+\n",
      "| C    | C(0) | C(1) | C(0) | C(1) |\n",
      "+------+------+------+------+------+\n",
      "| W(0) | 0.0  | 0.25 | 0.2  | 0.8  |\n",
      "+------+------+------+------+------+\n",
      "| W(1) | 1.0  | 0.75 | 0.8  | 0.2  |\n",
      "+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "m_model = BayesianModel([('B', 'MO'), ('B', 'W'), ('B', 'M'),('C', 'MO'), ('C', 'W'), ('C', 'M'), ('W', 'M'), ('MO', 'M')])\n",
    "m_model.fit(samples_25, estimator=MaximumLikelihoodEstimator)\n",
    "for cpd in m_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results and answer the following questions:\n",
    "1. How many parameters are there in the CPD tables?\n",
    "2. Keeping in mind that the probability of each column in a CPT must add to 1, how many free parameters must be fit for this model. \n",
    "3. Given the number of parameters, and the sample size of 25 cases, is this MLE problem under-determined and why? \n",
    "4. Notice the number of 0.0 and 1.0 parameter values. Is this evidence of an under-fit model, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1:  68    \n",
    "ANS 2:  42      \n",
    "ANS 3:  yes it is underdetermined, since there are more parameters than data points \n",
    "ANS 4:  yes, this is evidence of an underfit model since no outcome should be absolutely certain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will estimate the CPD parameters using a **Bayesian estimator**. For this first estimate use the following moderately weak and uniform prior distributions (pseudo counts):\n",
    "\n",
    "- C: [3,3]\n",
    "- B: [3,3]\n",
    "- W: [[3,3,3,3], [3,3,3,3]]\n",
    "- MO: [[3,3,3,3], [3,3,3,3]]\n",
    "- M: [[2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]]\n",
    "\n",
    "In the cell below create and execute the code to perform Bayes estimation and display the CPD parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPD of B:\n",
      "+------+----------+\n",
      "| B(0) | 0.419355 |\n",
      "+------+----------+\n",
      "| B(1) | 0.580645 |\n",
      "+------+----------+\n",
      "CPD of MO:\n",
      "+-------+------+------+--------+--------------------+\n",
      "| B     | B(0) | B(0) | B(1)   | B(1)               |\n",
      "+-------+------+------+--------+--------------------+\n",
      "| C     | C(0) | C(1) | C(0)   | C(1)               |\n",
      "+-------+------+------+--------+--------------------+\n",
      "| MO(0) | 0.75 | 0.5  | 0.1875 | 0.2727272727272727 |\n",
      "+-------+------+------+--------+--------------------+\n",
      "| MO(1) | 0.25 | 0.5  | 0.8125 | 0.7272727272727273 |\n",
      "+-------+------+------+--------+--------------------+\n",
      "CPD of W:\n",
      "+------+------+------+--------+---------------------+\n",
      "| B    | B(0) | B(0) | B(1)   | B(1)                |\n",
      "+------+------+------+--------+---------------------+\n",
      "| C    | C(0) | C(1) | C(0)   | C(1)                |\n",
      "+------+------+------+--------+---------------------+\n",
      "| W(0) | 0.25 | 0.4  | 0.3125 | 0.6363636363636364  |\n",
      "+------+------+------+--------+---------------------+\n",
      "| W(1) | 0.75 | 0.6  | 0.6875 | 0.36363636363636365 |\n",
      "+------+------+------+--------+---------------------+\n",
      "CPD of M:\n",
      "+------+--------------------+---------------------+--------------------+--------------------+---------------------+---------------------+--------------------+-------+--------------------+--------------------+-------+---------------------+--------------------+--------------------+-------+---------------------+\n",
      "| B    | B(0)               | B(0)                | B(0)               | B(0)               | B(0)                | B(0)                | B(0)               | B(0)  | B(1)               | B(1)               | B(1)  | B(1)                | B(1)               | B(1)               | B(1)  | B(1)                |\n",
      "+------+--------------------+---------------------+--------------------+--------------------+---------------------+---------------------+--------------------+-------+--------------------+--------------------+-------+---------------------+--------------------+--------------------+-------+---------------------+\n",
      "| C    | C(0)               | C(0)                | C(0)               | C(0)               | C(1)                | C(1)                | C(1)               | C(1)  | C(0)               | C(0)               | C(0)  | C(0)                | C(1)               | C(1)               | C(1)  | C(1)                |\n",
      "+------+--------------------+---------------------+--------------------+--------------------+---------------------+---------------------+--------------------+-------+--------------------+--------------------+-------+---------------------+--------------------+--------------------+-------+---------------------+\n",
      "| MO   | MO(0)              | MO(0)               | MO(1)              | MO(1)              | MO(0)               | MO(0)               | MO(1)              | MO(1) | MO(0)              | MO(0)              | MO(1) | MO(1)               | MO(0)              | MO(0)              | MO(1) | MO(1)               |\n",
      "+------+--------------------+---------------------+--------------------+--------------------+---------------------+---------------------+--------------------+-------+--------------------+--------------------+-------+---------------------+--------------------+--------------------+-------+---------------------+\n",
      "| W    | W(0)               | W(1)                | W(0)               | W(1)               | W(0)                | W(1)                | W(0)               | W(1)  | W(0)               | W(1)               | W(0)  | W(1)                | W(0)               | W(1)               | W(0)  | W(1)                |\n",
      "+------+--------------------+---------------------+--------------------+--------------------+---------------------+---------------------+--------------------+-------+--------------------+--------------------+-------+---------------------+--------------------+--------------------+-------+---------------------+\n",
      "| M(0) | 0.3333333333333333 | 0.6666666666666666  | 0.3333333333333333 | 0.3333333333333333 | 0.2857142857142857  | 0.2857142857142857  | 0.3333333333333333 | 0.25  | 0.3333333333333333 | 0.3333333333333333 | 0.25  | 0.14285714285714285 | 0.3333333333333333 | 0.3333333333333333 | 0.2   | 0.2857142857142857  |\n",
      "+------+--------------------+---------------------+--------------------+--------------------+---------------------+---------------------+--------------------+-------+--------------------+--------------------+-------+---------------------+--------------------+--------------------+-------+---------------------+\n",
      "| M(1) | 0.3333333333333333 | 0.16666666666666666 | 0.3333333333333333 | 0.3333333333333333 | 0.42857142857142855 | 0.42857142857142855 | 0.3333333333333333 | 0.5   | 0.3333333333333333 | 0.3333333333333333 | 0.25  | 0.14285714285714285 | 0.3333333333333333 | 0.3333333333333333 | 0.4   | 0.2857142857142857  |\n",
      "+------+--------------------+---------------------+--------------------+--------------------+---------------------+---------------------+--------------------+-------+--------------------+--------------------+-------+---------------------+--------------------+--------------------+-------+---------------------+\n",
      "| M(2) | 0.3333333333333333 | 0.16666666666666666 | 0.3333333333333333 | 0.3333333333333333 | 0.2857142857142857  | 0.2857142857142857  | 0.3333333333333333 | 0.25  | 0.3333333333333333 | 0.3333333333333333 | 0.5   | 0.7142857142857143  | 0.3333333333333333 | 0.3333333333333333 | 0.4   | 0.42857142857142855 |\n",
      "+------+--------------------+---------------------+--------------------+--------------------+---------------------+---------------------+--------------------+-------+--------------------+--------------------+-------+---------------------+--------------------+--------------------+-------+---------------------+\n",
      "CPD of C:\n",
      "+------+----------+\n",
      "| C(0) | 0.612903 |\n",
      "+------+----------+\n",
      "| C(1) | 0.387097 |\n",
      "+------+----------+\n"
     ]
    }
   ],
   "source": [
    "bayes_m_model = BayesianModel([('B', 'MO'), ('B', 'W'), ('B', 'M'),('C', 'MO'), ('C', 'W'), ('C', 'M'), ('W', 'M'), ('MO', 'M')])\n",
    "\n",
    "# Learing CPDs using Bayesian Estimators\n",
    "pseudo_counts = {'C': [[3],[3]], 'B':[[3],[3]], 'W':[[3,3,3,3],[3,3,3,3]], 'MO':[[3,3,3,3],[3,3,3,3]], 'M':[[2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]]}\n",
    "bayes_m_model.fit(samples_25, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=pseudo_counts)\n",
    "for cpd in bayes_m_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus your attention on the M and W CPDs. In terms of extreme values, how does the table computed with the Bayesian method compare to the table computed with MLE? Is this behavior evidence of the regularization property of the Bayesian estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1: The tables generated by the bayesian method do not contain any extreme values such as 1 or 0 as compared to the tables generated with MLE method.     \n",
    "ANS 2: The Bayesian method avoids these extreme values by using regularization to constrain the probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next verify that the independencies of all the variables in your model are correct using the `local_independencies` method. Create and execute the code in the cell below to display the independencies in the CPD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(B _|_ C)\n",
       "(C _|_ B)\n",
       "(W _|_ MO | C, B)\n",
       "(MO _|_ W | C, B)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_m_model.local_independencies(['B','C','W','MO','M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is your graph an I-map of the factorized distribution and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: Yes, the graphical model is an I-map since all of the independencies depicted in the graphical model are also part of the original factorized distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to perform inference on your model. Use the belief propagation method to query the M. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| M   |   phi(M) |\n",
      "+=====+==========+\n",
      "| M_0 |   0.3115 |\n",
      "+-----+----------+\n",
      "| M_1 |   0.2838 |\n",
      "+-----+----------+\n",
      "| M_2 |   0.4047 |\n",
      "+-----+----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pgmpy\\factors\\discrete\\DiscreteFactor.py:586: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  phi.values = phi.values[slice_]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pgmpy\\factors\\discrete\\DiscreteFactor.py:598: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  phi1.values = phi1.values[slice_]\n"
     ]
    }
   ],
   "source": [
    "from pgmpy.inference import BeliefPropagation\n",
    "m_belief = BeliefPropagation(bayes_m_model)\n",
    "m_b_prior_q = m_belief.query(variables=['M'])\n",
    "print(m_b_prior_q['M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this resulting marginal distribution to the marginal distribution you obtained for the same query in the previous homework using the CDP tables provided. How do these distribution differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: The original has higher probability for M_2 by more than .1, while the probabilties for M_0 and M_1 are lower in the original. The relative order of distribution is the same for both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will estimate the CPD parameters using the Bayesian estimator with a moderately weak but biased prior distribution. Such a prior distribution can be constructed from some combination of data from previous murder cases and the opinions of several investigators (experts). For this first estimate use the following prior distributions (pseudo counts):\n",
    "\n",
    "- C: [[8], [2]]\n",
    "- B: [[2],[8]]\n",
    "- W: [[2,4,2,3], [4,2,4,3]]\n",
    "- MO: [[3,2,4,3], [3,4,2,3]]\n",
    "- M: [[1,1,1,1,4,4,4,4,1,1,1,1,2,2,2,2], [1,1,1,1,1,1,1,1,4,4,4,4,2,2,2,2], [4,4,4,4,1,1,1,1,1,1,1,1,1,1,1,1]]\n",
    "\n",
    "In the cell below create and execute the code to perform Bayes estimation and display the CPD parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPD of B:\n",
      "+------+----------+\n",
      "| B(0) | 0.342857 |\n",
      "+------+----------+\n",
      "| B(1) | 0.657143 |\n",
      "+------+----------+\n",
      "CPD of MO:\n",
      "+-------+------+------+------+--------------------+\n",
      "| B     | B(0) | B(0) | B(1) | B(1)               |\n",
      "+-------+------+------+------+--------------------+\n",
      "| C     | C(0) | C(1) | C(0) | C(1)               |\n",
      "+-------+------+------+------+--------------------+\n",
      "| MO(0) | 0.75 | 0.4  | 0.25 | 0.2727272727272727 |\n",
      "+-------+------+------+------+--------------------+\n",
      "| MO(1) | 0.25 | 0.6  | 0.75 | 0.7272727272727273 |\n",
      "+-------+------+------+------+--------------------+\n",
      "CPD of W:\n",
      "+------+---------------------+------+------+---------------------+\n",
      "| B    | B(0)                | B(0) | B(1) | B(1)                |\n",
      "+------+---------------------+------+------+---------------------+\n",
      "| C    | C(0)                | C(1) | C(0) | C(1)                |\n",
      "+------+---------------------+------+------+---------------------+\n",
      "| W(0) | 0.16666666666666666 | 0.5  | 0.25 | 0.6363636363636364  |\n",
      "+------+---------------------+------+------+---------------------+\n",
      "| W(1) | 0.8333333333333334  | 0.5  | 0.75 | 0.36363636363636365 |\n",
      "+------+---------------------+------+------+---------------------+\n",
      "CPD of M:\n",
      "+------+---------------------+---------------------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+-------+-------+--------------------+--------------------+\n",
      "| B    | B(0)                | B(0)                | B(0)                | B(0)                | B(0)  | B(0)                | B(0)                | B(0)  | B(1)                | B(1)                | B(1)  | B(1)                | B(1)  | B(1)  | B(1)               | B(1)               |\n",
      "+------+---------------------+---------------------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+-------+-------+--------------------+--------------------+\n",
      "| C    | C(0)                | C(0)                | C(0)                | C(0)                | C(1)  | C(1)                | C(1)                | C(1)  | C(0)                | C(0)                | C(0)  | C(0)                | C(1)  | C(1)  | C(1)               | C(1)               |\n",
      "+------+---------------------+---------------------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+-------+-------+--------------------+--------------------+\n",
      "| MO   | MO(0)               | MO(0)               | MO(1)               | MO(1)               | MO(0) | MO(0)               | MO(1)               | MO(1) | MO(0)               | MO(0)               | MO(1) | MO(1)               | MO(0) | MO(0) | MO(1)              | MO(1)              |\n",
      "+------+---------------------+---------------------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+-------+-------+--------------------+--------------------+\n",
      "| W    | W(0)                | W(1)                | W(0)                | W(1)                | W(0)  | W(1)                | W(0)                | W(1)  | W(0)                | W(1)                | W(0)  | W(1)                | W(0)  | W(1)  | W(0)               | W(1)               |\n",
      "+------+---------------------+---------------------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+-------+-------+--------------------+--------------------+\n",
      "| M(0) | 0.16666666666666666 | 0.5833333333333334  | 0.16666666666666666 | 0.16666666666666666 | 0.4   | 0.5714285714285714  | 0.6666666666666666  | 0.5   | 0.16666666666666666 | 0.16666666666666666 | 0.125 | 0.07142857142857142 | 0.4   | 0.4   | 0.2222222222222222 | 0.3333333333333333 |\n",
      "+------+---------------------+---------------------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+-------+-------+--------------------+--------------------+\n",
      "| M(1) | 0.16666666666666666 | 0.08333333333333333 | 0.16666666666666666 | 0.16666666666666666 | 0.2   | 0.2857142857142857  | 0.16666666666666666 | 0.375 | 0.6666666666666666  | 0.6666666666666666  | 0.5   | 0.2857142857142857  | 0.4   | 0.4   | 0.4444444444444444 | 0.3333333333333333 |\n",
      "+------+---------------------+---------------------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+-------+-------+--------------------+--------------------+\n",
      "| M(2) | 0.6666666666666666  | 0.3333333333333333  | 0.6666666666666666  | 0.6666666666666666  | 0.4   | 0.14285714285714285 | 0.16666666666666666 | 0.125 | 0.16666666666666666 | 0.16666666666666666 | 0.375 | 0.6428571428571429  | 0.2   | 0.2   | 0.3333333333333333 | 0.3333333333333333 |\n",
      "+------+---------------------+---------------------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+---------------------+-------+---------------------+-------+-------+--------------------+--------------------+\n",
      "CPD of C:\n",
      "+------+----------+\n",
      "| C(0) | 0.685714 |\n",
      "+------+----------+\n",
      "| C(1) | 0.314286 |\n",
      "+------+----------+\n"
     ]
    }
   ],
   "source": [
    "bayes_m_model = BayesianModel([('B', 'MO'), ('B', 'W'), ('B', 'M'),('C', 'MO'), ('C', 'W'), ('C', 'M'), ('W', 'M'), ('MO', 'M')])\n",
    "\n",
    "# Learing CPDs using Bayesian Estimators\n",
    "pseudo_counts = {'C': [[8], [2]], 'B':[[2],[8]], 'W':[[2,4,2,3], [4,2,4,3]], 'MO': [[3,2,4,3], [3,4,2,3]], 'M':[[1,1,1,1,4,4,4,4,1,1,1,1,2,2,2,2], [1,1,1,1,1,1,1,1,4,4,4,4,2,2,2,2], [4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,1]]}\n",
    "bayes_m_model.fit(samples_25, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=pseudo_counts)\n",
    "for cpd in bayes_m_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the parameters tables computed with the biased prior to those estimated with a uniform prior. How are these different, and is this expected given the change in prior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: The parameter tables computed with biased prior weigh the probabilities more heavily towards those parameter values with stronger priors as compared to the uniform priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, how much does the prior matter in terms of inference? Use the belief propagation method to query the M variable and display the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "| M   |   phi(M) |\n",
      "+=====+==========+\n",
      "| M_0 |   0.2685 |\n",
      "+-----+----------+\n",
      "| M_1 |   0.3279 |\n",
      "+-----+----------+\n",
      "| M_2 |   0.4036 |\n",
      "+-----+----------+\n"
     ]
    }
   ],
   "source": [
    "m_belief = BeliefPropagation(bayes_m_model)\n",
    "m_b_prior_q = m_belief.query(variables=['M'])\n",
    "print(m_b_prior_q['M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this marginal distribution to the one obtained with the a uniform prior. Would you say these differences are significant, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:Numeric values are only slightly different between the two cases while maintaining the same order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps more data will improve the estimation of the model parameters, particularly for the maximum likelihood method. In the cell below compute a new data set with 250 cases. Use a random seed value of 5678. Be sure to give your new data frame a different name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>B</th>\n",
       "      <th>W</th>\n",
       "      <th>MO</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     C  B  W  MO  M\n",
       "0    0  0  0   0  0\n",
       "1    0  1  1   1  2\n",
       "2    0  1  1   1  2\n",
       "3    0  1  0   1  2\n",
       "4    0  0  1   0  0\n",
       "5    0  0  1   0  0\n",
       "6    0  1  0   1  2\n",
       "7    0  1  0   1  2\n",
       "8    0  1  1   1  2\n",
       "9    0  1  0   1  2\n",
       "10   0  1  1   1  2\n",
       "11   1  1  0   0  1\n",
       "12   0  0  1   0  0\n",
       "13   1  0  1   0  1\n",
       "14   0  0  1   0  0\n",
       "15   1  1  0   0  2\n",
       "16   1  0  1   0  1\n",
       "17   0  0  1   0  0\n",
       "18   1  1  0   1  1\n",
       "19   0  0  1   0  0\n",
       "20   1  1  0   1  1\n",
       "21   0  0  1   0  0\n",
       "22   0  0  1   0  0\n",
       "23   1  1  0   1  2\n",
       "24   1  1  0   1  2\n",
       "25   0  1  1   0  2\n",
       "26   0  1  1   1  2\n",
       "27   0  0  1   0  0\n",
       "28   1  0  0   0  1\n",
       "29   1  0  0   1  1\n",
       "..  .. .. ..  .. ..\n",
       "220  0  1  0   1  2\n",
       "221  0  0  0   0  0\n",
       "222  0  1  0   1  2\n",
       "223  0  0  1   0  0\n",
       "224  0  0  1   0  0\n",
       "225  1  1  0   0  2\n",
       "226  0  1  1   1  2\n",
       "227  0  0  1   0  0\n",
       "228  1  1  0   0  2\n",
       "229  0  0  1   0  0\n",
       "230  1  1  1   1  2\n",
       "231  0  0  1   0  0\n",
       "232  1  1  1   1  1\n",
       "233  0  0  1   0  0\n",
       "234  0  0  1   0  0\n",
       "235  0  0  1   0  0\n",
       "236  0  1  1   1  2\n",
       "237  0  1  0   1  2\n",
       "238  1  0  1   0  1\n",
       "239  0  1  0   0  2\n",
       "240  0  1  1   0  2\n",
       "241  0  1  0   1  2\n",
       "242  1  0  1   1  1\n",
       "243  0  0  1   0  0\n",
       "244  1  1  0   1  2\n",
       "245  1  0  1   0  1\n",
       "246  1  1  1   0  2\n",
       "247  1  0  0   0  1\n",
       "248  0  1  1   1  2\n",
       "249  0  1  1   1  2\n",
       "\n",
       "[250 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nsamps = 250\n",
    "samples_250 = simulate_from_DAG(murder_model, nsamps = nsamps, set_seed = 5678)\n",
    "samples_250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the model parameters using the 250 sample dataset and the **maximum likelihood estimator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for B\n",
      "WARNING:root:Replacing existing CPD for C\n",
      "WARNING:root:Replacing existing CPD for M\n",
      "WARNING:root:Replacing existing CPD for MO\n",
      "WARNING:root:Replacing existing CPD for W\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPD of B:\n",
      "+------+-------+\n",
      "| B(0) | 0.444 |\n",
      "+------+-------+\n",
      "| B(1) | 0.556 |\n",
      "+------+-------+\n",
      "CPD of C:\n",
      "+------+-----+\n",
      "| C(0) | 0.7 |\n",
      "+------+-----+\n",
      "| C(1) | 0.3 |\n",
      "+------+-----+\n",
      "CPD of M:\n",
      "+------+-------+-------+--------------------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+---------------------+-------+\n",
      "| B    | B(0)  | B(0)  | B(0)               | B(0)               | B(0)  | B(0)  | B(0)  | B(0)  | B(1)  | B(1)  | B(1)  | B(1)  | B(1)  | B(1)  | B(1)                | B(1)  |\n",
      "+------+-------+-------+--------------------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+---------------------+-------+\n",
      "| C    | C(0)  | C(0)  | C(0)               | C(0)               | C(1)  | C(1)  | C(1)  | C(1)  | C(0)  | C(0)  | C(0)  | C(0)  | C(1)  | C(1)  | C(1)                | C(1)  |\n",
      "+------+-------+-------+--------------------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+---------------------+-------+\n",
      "| MO   | MO(0) | MO(0) | MO(1)              | MO(1)              | MO(0) | MO(0) | MO(1) | MO(1) | MO(0) | MO(0) | MO(1) | MO(1) | MO(0) | MO(0) | MO(1)               | MO(1) |\n",
      "+------+-------+-------+--------------------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+---------------------+-------+\n",
      "| W    | W(0)  | W(1)  | W(0)               | W(1)               | W(0)  | W(1)  | W(0)  | W(1)  | W(0)  | W(1)  | W(0)  | W(1)  | W(0)  | W(1)  | W(0)                | W(1)  |\n",
      "+------+-------+-------+--------------------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+---------------------+-------+\n",
      "| M(0) | 1.0   | 1.0   | 0.3333333333333333 | 0.3333333333333333 | 0.0   | 0.0   | 0.0   | 0.0   | 0.0   | 0.0   | 0.0   | 0.0   | 0.0   | 0.0   | 0.0                 | 0.0   |\n",
      "+------+-------+-------+--------------------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+---------------------+-------+\n",
      "| M(1) | 0.0   | 0.0   | 0.3333333333333333 | 0.3333333333333333 | 1.0   | 1.0   | 1.0   | 1.0   | 0.0   | 0.0   | 0.0   | 0.0   | 0.375 | 0.4   | 0.43478260869565216 | 0.4   |\n",
      "+------+-------+-------+--------------------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+---------------------+-------+\n",
      "| M(2) | 0.0   | 0.0   | 0.3333333333333333 | 0.3333333333333333 | 0.0   | 0.0   | 0.0   | 0.0   | 1.0   | 1.0   | 1.0   | 1.0   | 0.625 | 0.6   | 0.5652173913043478  | 0.6   |\n",
      "+------+-------+-------+--------------------+--------------------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+---------------------+-------+\n",
      "CPD of MO:\n",
      "+-------+------+--------------------+---------------------+--------------------+\n",
      "| B     | B(0) | B(0)               | B(1)                | B(1)               |\n",
      "+-------+------+--------------------+---------------------+--------------------+\n",
      "| C     | C(0) | C(1)               | C(0)                | C(1)               |\n",
      "+-------+------+--------------------+---------------------+--------------------+\n",
      "| MO(0) | 1.0  | 0.6896551724137931 | 0.11827956989247312 | 0.2826086956521739 |\n",
      "+-------+------+--------------------+---------------------+--------------------+\n",
      "| MO(1) | 0.0  | 0.3103448275862069 | 0.8817204301075269  | 0.717391304347826  |\n",
      "+-------+------+--------------------+---------------------+--------------------+\n",
      "CPD of W:\n",
      "+------+---------------------+--------------------+--------------------+---------------------+\n",
      "| B    | B(0)                | B(0)               | B(1)               | B(1)                |\n",
      "+------+---------------------+--------------------+--------------------+---------------------+\n",
      "| C    | C(0)                | C(1)               | C(0)               | C(1)                |\n",
      "+------+---------------------+--------------------+--------------------+---------------------+\n",
      "| W(0) | 0.12195121951219512 | 0.3793103448275862 | 0.3870967741935484 | 0.6739130434782609  |\n",
      "+------+---------------------+--------------------+--------------------+---------------------+\n",
      "| W(1) | 0.8780487804878049  | 0.6206896551724138 | 0.6129032258064516 | 0.32608695652173914 |\n",
      "+------+---------------------+--------------------+--------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "m_model.fit(samples_250, estimator=MaximumLikelihoodEstimator)\n",
    "for cpd in m_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these results to the MLE results you computed with 25 data cases. Are their fewer extreme values? But, does the presence of extreme values still indicate the model is under-fit despite an order of magnitude increase in the number of data cases? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1: Yes, there are fewer extreme values in these CPDs.\n",
    "\n",
    "ANS 2: Yes, the presence of extreme values indicates that this model is still under-fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will compare the MLE values to those produced by the **Bayesian estimator** using the same uniform prior as the first Bayes estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Replacing existing CPD for B\n",
      "WARNING:root:Replacing existing CPD for MO\n",
      "WARNING:root:Replacing existing CPD for W\n",
      "WARNING:root:Replacing existing CPD for M\n",
      "WARNING:root:Replacing existing CPD for C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPD of B:\n",
      "+------+----------+\n",
      "| B(0) | 0.445312 |\n",
      "+------+----------+\n",
      "| B(1) | 0.554688 |\n",
      "+------+----------+\n",
      "CPD of C:\n",
      "+------+----------+\n",
      "| C(0) | 0.695312 |\n",
      "+------+----------+\n",
      "| C(1) | 0.304688 |\n",
      "+------+----------+\n",
      "CPD of M:\n",
      "+------+-------+---------------------+--------------------+--------------------+---------------------+---------------------+-------+---------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+-------+\n",
      "| B    | B(0)  | B(0)                | B(0)               | B(0)               | B(0)                | B(0)                | B(0)  | B(0)                | B(1)               | B(1)                | B(1)                | B(1)                | B(1)                | B(1)                | B(1)                | B(1)  |\n",
      "+------+-------+---------------------+--------------------+--------------------+---------------------+---------------------+-------+---------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+-------+\n",
      "| C    | C(0)  | C(0)                | C(0)               | C(0)               | C(1)                | C(1)                | C(1)  | C(1)                | C(0)               | C(0)                | C(0)                | C(0)                | C(1)                | C(1)                | C(1)                | C(1)  |\n",
      "+------+-------+---------------------+--------------------+--------------------+---------------------+---------------------+-------+---------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+-------+\n",
      "| MO   | MO(0) | MO(0)               | MO(1)              | MO(1)              | MO(0)               | MO(0)               | MO(1) | MO(1)               | MO(0)              | MO(0)               | MO(1)               | MO(1)               | MO(0)               | MO(0)               | MO(1)               | MO(1) |\n",
      "+------+-------+---------------------+--------------------+--------------------+---------------------+---------------------+-------+---------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+-------+\n",
      "| W    | W(0)  | W(1)                | W(0)               | W(1)               | W(0)                | W(1)                | W(0)  | W(1)                | W(0)               | W(1)                | W(0)                | W(1)                | W(0)                | W(1)                | W(0)                | W(1)  |\n",
      "+------+-------+---------------------+--------------------+--------------------+---------------------+---------------------+-------+---------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+-------+\n",
      "| M(0) | 0.75  | 0.9487179487179487  | 0.3333333333333333 | 0.3333333333333333 | 0.15384615384615385 | 0.10526315789473684 | 0.2   | 0.18181818181818182 | 0.2222222222222222 | 0.14285714285714285 | 0.05128205128205128 | 0.03636363636363636 | 0.14285714285714285 | 0.18181818181818182 | 0.06896551724137931 | 0.125 |\n",
      "+------+-------+---------------------+--------------------+--------------------+---------------------+---------------------+-------+---------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+-------+\n",
      "| M(1) | 0.125 | 0.02564102564102564 | 0.3333333333333333 | 0.3333333333333333 | 0.6923076923076923  | 0.7894736842105263  | 0.6   | 0.6363636363636364  | 0.2222222222222222 | 0.14285714285714285 | 0.05128205128205128 | 0.03636363636363636 | 0.35714285714285715 | 0.36363636363636365 | 0.41379310344827586 | 0.375 |\n",
      "+------+-------+---------------------+--------------------+--------------------+---------------------+---------------------+-------+---------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+-------+\n",
      "| M(2) | 0.125 | 0.02564102564102564 | 0.3333333333333333 | 0.3333333333333333 | 0.15384615384615385 | 0.10526315789473684 | 0.2   | 0.18181818181818182 | 0.5555555555555556 | 0.7142857142857143  | 0.8974358974358975  | 0.9272727272727272  | 0.5                 | 0.45454545454545453 | 0.5172413793103449  | 0.5   |\n",
      "+------+-------+---------------------+--------------------+--------------------+---------------------+---------------------+-------+---------------------+--------------------+---------------------+---------------------+---------------------+---------------------+---------------------+---------------------+-------+\n",
      "CPD of MO:\n",
      "+-------+---------------------+---------------------+--------------------+--------------------+\n",
      "| B     | B(0)                | B(0)                | B(1)               | B(1)               |\n",
      "+-------+---------------------+---------------------+--------------------+--------------------+\n",
      "| C     | C(0)                | C(1)                | C(0)               | C(1)               |\n",
      "+-------+---------------------+---------------------+--------------------+--------------------+\n",
      "| MO(0) | 0.9659090909090909  | 0.6571428571428571  | 0.1414141414141414 | 0.3076923076923077 |\n",
      "+-------+---------------------+---------------------+--------------------+--------------------+\n",
      "| MO(1) | 0.03409090909090909 | 0.34285714285714286 | 0.8585858585858586 | 0.6923076923076923 |\n",
      "+-------+---------------------+---------------------+--------------------+--------------------+\n",
      "CPD of W:\n",
      "+------+---------------------+------+--------------------+---------------------+\n",
      "| B    | B(0)                | B(0) | B(1)               | B(1)                |\n",
      "+------+---------------------+------+--------------------+---------------------+\n",
      "| C    | C(0)                | C(1) | C(0)               | C(1)                |\n",
      "+------+---------------------+------+--------------------+---------------------+\n",
      "| W(0) | 0.14772727272727273 | 0.4  | 0.3939393939393939 | 0.6538461538461539  |\n",
      "+------+---------------------+------+--------------------+---------------------+\n",
      "| W(1) | 0.8522727272727273  | 0.6  | 0.6060606060606061 | 0.34615384615384615 |\n",
      "+------+---------------------+------+--------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "pseudo_counts = {'C': [[3],[3]], 'B':[[3],[3]], 'W':[[3,3,3,3],[3,3,3,3]], 'MO':[[3,3,3,3],[3,3,3,3]], 'M':[[2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]]}\n",
    "m_model.fit(samples_250, estimator=BayesianEstimator, prior_type='dirichlet', pseudo_counts=pseudo_counts)\n",
    "for cpd in m_model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of evidence of under-fitting, such as repeated parameter values, how does these estimates compare to the Bayes estimates using 25 cases? Also, are probability tables for the butler and the cook closer to the original values from DAG model used for the simulation, when compare to the parameters computed with the Bayes estimator from 25 cases? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1: Yes the incidence of repeated values is lower for this case than for the 25 value case, indicating an improvement in the under-fitting.\n",
    "\n",
    "ANS 2: Yes, the probability tables for the cook and butler are now closer to their actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Estimation of Parameters\n",
    "\n",
    "To gain a feel for how a prior distribution changes the parameter estimates you will perform random sampling of data from the DAG model and estimate a model parameter. As a first step, write a function(s) that random samples a dataset and then estimates the parameter, $\\theta$. Your function(s) should do the following:\n",
    "\n",
    "1. Use the DAG model you imported for the simulation creating each dataset realization. \n",
    "2. Arguments should include the $\\alpha$ and $\\beta$ prior pseudo counts.\n",
    "3. The parameter, $\\theta$ is estimated for the butler, B, table. \n",
    "4. The number of samples per realized dataset is 25. \n",
    "5. Compute 1,000 estimates of $\\theta$, using 1,000 independent sample datasets.\n",
    "6. Use an initial random seed of 345, and increase your seed value by 100 for each realization.\n",
    "7. Return an array-like data structure containing your 1,000 parameter estimates. \n",
    "\n",
    "Create the code in the cell below. Then execute your code for a **maximum likelihood estimate** of the 1,000 values of theta by setting $\\alpha$ and $\\beta$ both to 0, and save the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_theta(model, alpha, beta, num_samples, num_estimates, random_seed):\n",
    "    estimates = []\n",
    "    for i in range(num_estimates):\n",
    "        curr_samples = simulate_from_DAG(model, num_samples, set_seed = random_seed)\n",
    "        numerator = sum(curr_samples['B']) + alpha\n",
    "        denominator = num_samples + alpha + beta\n",
    "        estimates.append(numerator/float(denominator))\n",
    "        random_seed = random_seed + 100\n",
    "    return estimates\n",
    "\n",
    "mle_thetas = estimate_theta(m_model, 0, 0, 25, 1000, 345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to visualize the results as a histogram. Create a function to plot a histogram with of your parameter estimates using 50 bins and with x-axis limits of (0.2,0.9). Make sure to label your axes. Then, plot the histogram and examine the results. \n",
    "\n",
    "> **Note:** Since the DAG has a limited number of discrete valued notes, expect the histogram to have a number of discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_hist(data):\n",
    "    plt.hist(data, bins = 50)\n",
    "    plt.xlim((0.2,0.9))\n",
    "    \n",
    "plot_hist(mle_thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the dispersion of the parameter estimates and the most likely value (mode). Given that the parameter, $\\theta$, must be in the range $0.0 \\le \\theta \\le 1.0$, would you say there is significant dispersion in these estimates, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: Yes, there is quite a bit of dispersion since values are present along the entire x-axis. This is probably because there is no prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, simulate a new realization of the 1,000 datasets, estimating the parameters, $\\theta$ using a prior with pseudo counts, alpha = 6, beta = 4. Then, plot the histogram to compare with the previous results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prior_thetas = estimate_theta(m_model, 6, 4, 25, 1000, 345)\n",
    "plot_hist(prior_thetas)\n",
    "#prior_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How has adding this prior changed the characteristics of the distribution of the parameter, $\\theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: The dispersion for this set of values is less than before with the mode remaining the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will explore the learning properties of the Bayes estimator when very little data is available. You will compute realizations of datasets with just 5 samples and plot the histogram of the parameter estimates. Continue using a prior with pseudo counts, alpha = 6, beta = 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prior_thetas = estimate_theta(m_model, 6, 4, 5, 1000, 345)\n",
    "plot_hist(prior_thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the resulting histogram. The result has fewer discrete values that the histogram computed using a sample size of 25. But, are the dispersion and mode of these two distributions nearly the same and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:The dispersion is the same since alpha and beta are the same, but there are fewer discrete values since the number of samples per run is much lower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you will investigate the effect of a strong prior. A strong prior arises in cases where there is considerable experience with the problem. In such cases, the new observations only incrementally change the parameter estimates. \n",
    "\n",
    "Simulate a new realization of datasets with 25 samples each, estimating the parameters, $\\theta$ using a prior with pseudo counts, alpha = 16, beta = 24. Then, plot the histogram to compare with the previous results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prior_thetas = estimate_theta(m_model, 16, 24, 25, 1000, 345)\n",
    "plot_hist(prior_thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these results to the those obtained using the same prior with 25 samples per realization. What are the key differences between these distributions of the parameters, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:The dispersion for this case is much lower and the mode has shifted to the left because of the strong prior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2, Learning Structure\n",
    "\n",
    "Now you will explore how well the structure of the graph can be estimated. **Keep in mind that the graph used for the simulation is not a tree**. Answer the questions based on the results you find. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset simulated, you will now try estimating the model structure. Use the hill climb search algorithm with the BIC scoring function to estimate the model structure, using the dataset with 250 samples. Set a `numpy.random.seed` of 5566, before computing the model. Create and execute the code in the cell below to estimate the model structure and display the identified edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B', 'M'), ('M', 'C'), ('M', 'MO'), ('M', 'W')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(5566) \n",
    "from pgmpy.estimators import HillClimbSearch, BicScore, K2Score, StructureScore\n",
    "from pgmpy.models import BayesianModel\n",
    "est_bic = HillClimbSearch(samples_250, scoring_method=BicScore(samples_250))\n",
    "BIC_edges = est_bic.estimate(max_indegree=2).edges()\n",
    "BIC_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these edges. How does this model compare to the model used to simulate the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: This model differs quite a bit from the original model, only edges between M and other variables are present in this model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this structure fit? To answer this question you will need to compare the BIC score of the graph used for the simulation with the BIC score of the estimated structure. You must create a baseline DAG structure and compare the BIC score to the score of the estimated model. \n",
    "\n",
    "Notice that in practice, you will never know the true graph structure. Else, why estimate it? In such cases, the best you can do is test several models and select the one with the lowest BIC that also honors any constraints known from expert opinion. \n",
    "\n",
    "In the cell below create the code to compute and display the BIC score of both the graph used for the simulation and the estimated structure, using the 250 sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-691.4378654542542\n",
      "-625.4589810490882\n"
     ]
    }
   ],
   "source": [
    "print(BicScore(samples_250).score(m_model))\n",
    "print(BicScore(samples_250).score(BayesianModel(BIC_edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these BIC scores different and what does this mean in terms of how good the estimated model is? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: Yes, the bic scores are different, the original model has a better score since it is lower.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will apply the K2 score method to the 250 case dataset. In the cell below, create the code to use the hill climbing search with the K2 score to estimate and display the model structure. Set a `numpy.random.seed` of 6565, before computing the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 'M'), ('C', 'W'), ('B', 'MO'), ('M', 'B'), ('M', 'MO'), ('M', 'W')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(6565)\n",
    "est_K2S = HillClimbSearch(samples_250, scoring_method=K2Score(samples_250))\n",
    "K2S_edges = est_K2S.estimate(max_indegree=2).edges()\n",
    "K2S_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this graph structure any different from the one obtained with the BIC score and what does this mean in terms of the independency structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:This graph structure looks a little better than the one obtained from BIC score, it captures more of the edges from the original graph, but still differs significantly from the original graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compare the K2 score for the baseline DAG model with the estimated model using the 250 case dataset. In the cell below create and execute the code to compute and display these scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-655.6480031340966\n",
      "-622.8204332522461\n"
     ]
    }
   ],
   "source": [
    "print(K2Score(samples_250).score(m_model))\n",
    "print(K2Score(samples_250).score(BayesianModel(K2S_edges)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these K2 scores different and what does this indicate about the estimated model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:Yes, the K2 scores are different, the original model has a better score since it is lower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below create and execute the code to display the independencies of the graph structure you have found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(B _|_ C | M)\n",
       "(W _|_ MO, M | C, B)\n",
       "(MO _|_ W, M | C, B)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_K2S.estimate().local_independencies(['B', 'C', 'W', 'MO', 'M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these local independencies have some problematic characteristics. What statement can you make about these problems for the murderer variable, M?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: It doesn't make sense for weapon and motive to be independent of the murderer, since the different values for murderers have different probabilities for each of the values of weapon and motive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps, a larger dataset will yield better DAGs? In the cell below, compute a dataset with 25,000 samples using the DAG model. Use a random seed of 9898. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_25000 = simulate_from_DAG(m_model, nsamps = 25000, set_seed = 9898)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the larger dataset available, you can now determine if using 2 orders of magnitude more data improves the model structure estimates. In the cell below, use the hill climb search algorithm with the BIC scoring function to estimate the model structure. Set a `numpy.random.seed` of 4567, before computing the model. Make sure you give you model a unique name so you can make comparisons latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 'MO'),\n",
       " ('C', 'B'),\n",
       " ('B', 'MO'),\n",
       " ('W', 'M'),\n",
       " ('W', 'C'),\n",
       " ('M', 'B'),\n",
       " ('M', 'C')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(4567)\n",
    "est_bic_big = HillClimbSearch(samples_25000, scoring_method=BicScore(samples_25000))\n",
    "BIC_edges_big = est_bic_big.estimate(max_indegree=2).edges()\n",
    "BIC_edges_big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the 25,000 sample data set with the hill climb search algorithm using the K2 scoring function to estimate the model structure. Set a `numpy.random.seed` of 765, before computing the model. Make sure you give you model a unique name so you can make comparisons latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', 'M'), ('C', 'MO'), ('C', 'W'), ('B', 'M'), ('B', 'MO'), ('M', 'W')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nr.seed(765)\n",
    "est_K2S_big = HillClimbSearch(samples_25000, scoring_method=K2Score(samples_25000))\n",
    "K2S_edges_big = est_K2S_big.estimate(max_indegree=2).edges()\n",
    "K2S_edges_big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two scoring methods have arrived at different models, even when a larger dataset is used.  What are some key differences in these models and with the original models? **Hint:** Look at the numbers of directed edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: With the larger sample, the BIC scoring method yields 3 more edges in the graph, whereas the number of edges from the K2 score remain the same. The graph from the K2 score method still appears more reasonable as compared to the original graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K2 score models have been created using a Dirichlet uniform prior, starting with a completely unconnected model. See the [pgmpy documentation for more details](http://pgmpy.org/estimators.html).   \n",
    "\n",
    "The addition of a prior in the form of an initial DAG model might make a difference. In the cell below a simple initial model is defined. You can specify an initial model using the `start` argument to the `estimate` method. \n",
    "\n",
    "Using the 25,000 case dataset and the initial model, use the K2 score to find a model structure. Set a `numpy.random.seed` of 543, before computing the model. Make sure you give you model a unique name so you can make comparisons latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('W', 'M'),\n",
       " ('MO', 'M'),\n",
       " ('B', 'M'),\n",
       " ('B', 'MO'),\n",
       " ('B', 'W'),\n",
       " ('C', 'M'),\n",
       " ('C', 'MO'),\n",
       " ('C', 'W')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Define the initial network structure.\n",
    "start = BayesianModel([('W','M'), ('MO','M'), ('B',\"M\"), ('C',\"M\")])\n",
    "\n",
    "## Define code and find model structure\n",
    "est_K2S_prior = HillClimbSearch(samples_25000, scoring_method=K2Score(samples_25000))\n",
    "K2S_edges_prior = est_K2S_prior.estimate(max_indegree=2, start=start).edges()\n",
    "K2S_edges_prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the use of the prior or initial model changed the result? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS: Yes, using the prior gives us the a model that matches the original model exactly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compare the BIC and K2 scores of the three models you created with the K2 and BIC score methods on the 25,000 case dataset. In the cell below create and execute the code to compute and display these 6 scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-634.9618377603881\n",
      "-629.4229755578021\n",
      "-632.9192682113727\n",
      "-628.4516134472877\n",
      "-691.4378654542542\n",
      "-655.6480031340967\n"
     ]
    }
   ],
   "source": [
    "print(BicScore(samples_250).score(BayesianModel(BIC_edges_big)))\n",
    "print(K2Score(samples_250).score(BayesianModel(BIC_edges_big)))\n",
    "print(BicScore(samples_250).score(BayesianModel(K2S_edges_big)))\n",
    "print(K2Score(samples_250).score(BayesianModel(K2S_edges_big)))\n",
    "print(BicScore(samples_250).score(BayesianModel(K2S_edges_prior)))\n",
    "print(K2Score(samples_250).score(BayesianModel(K2S_edges_prior)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results. Do the results indicate any one model is substantially better than the others? Does this outcome help explain the ambiguity you have seen in estimating model structure, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1: Yes, the model with the prior using K2 score is substantially better than the others.\n",
    "ANS 2: Yes, these results show that if the search for the model structure is constrained, such as with a prior, the search can derive much better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create and execute the code in the cell below, to print the local independencies of the models estimated using the K2 and BIC score methods on the 25,000 case dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(MO _|_ W | C, M, B)\n",
      "\n",
      "\n",
      "(B _|_ C)\n",
      "(C _|_ B)\n",
      "(W _|_ MO | C, B)\n",
      "(MO _|_ W | C, B)\n",
      "\n",
      "\n",
      "(B _|_ C)\n",
      "(C _|_ B)\n",
      "(W _|_ MO | C, B)\n",
      "(MO _|_ W | C, B)\n"
     ]
    }
   ],
   "source": [
    "print(est_bic_big.estimate().local_independencies(['B', 'C', 'W', 'MO', 'M']))\n",
    "print('\\n')\n",
    "print(est_K2S_big.estimate().local_independencies(['B', 'C', 'W', 'MO', 'M']))\n",
    "print('\\n')\n",
    "print(est_K2S_prior.estimate().local_independencies(['B', 'C', 'W', 'MO', 'M']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the local indepenencies different? Which structure makes more sense when compared to the original DAG used for the simulation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1: The models using the K2 score and K2 score with prior reveal 4 local independencies while the model using the BIC score shows only one local independency.\n",
    "ANS 2: The models using the K2 score make more sense since they capture the actual independencies from the original DAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
