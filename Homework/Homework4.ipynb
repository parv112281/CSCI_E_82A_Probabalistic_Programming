{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "## Graphical Parameters and Model Structure\n",
    "\n",
    "In the previous homework, you performed queries on a graphical model of possible murders and murder weapons. Now, you will estimate model parameters and structure using data.   \n",
    "\n",
    "As a reminder, the joint probability distribution is:\n",
    "\n",
    "$$p(B,C,W,MO,M)$$     \n",
    "\n",
    "where the letters indicate the following variables;   \n",
    "$B = $ butler committed the crime, {not murderer, murderer},   \n",
    "$C = $ cook committed the crime, {not murderer, murderer},    \n",
    "$W = $ choice of weapon, {poison, knife}, conditional on butler and cook,  \n",
    "$MO = $motive for the murder, {no motive, has motive}, conditional on butler and cook,   \n",
    "$M = $ murderer {butler or cook, third party alone}.    \n",
    "\n",
    "We have determined that the joint distribution can be factored:\n",
    "\n",
    "$$p(B,C,BW,CW,M) = p(B)\\ p(C)\\ p(W\\ |\\ B, C)\\ p(MO\\ |\\ B,C)\\ p(M\\ |\\ B,C,MO,W)$$  \n",
    "\n",
    "A graph of the model is shown below. \n",
    "\n",
    "<img src=\"MurderDirected.JPG\" alt=\"Drawing\" style=\"width:500px; height:300px\"/>\n",
    "<center> DAG for murder evidence </center>\n",
    "\n",
    "Notice that the skeleton of this graph does not have a tree structure. This fact will limit how well estimation algorithms will work, particularly for graph structure. Keep this fact in mind as you proceed. \n",
    "\n",
    "As a first step execute the code in the below to simulate the 25 cases from the Bayesian directed model you have previously created. Examine the code to see the CPD tables for this simulation. \n",
    "\n",
    "> **Note:** You must change the name of the pickled model file in the `open` statement to match the file name you are using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Simulate the binary tables\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "import pickle\n",
    "\n",
    "## Load the model from a file\n",
    "with open('my_model.pickle', 'rb') as pkl:\n",
    "    murder_model = pickle.load(pkl)\n",
    "print('The model loaded correctly: {}'.format(murder_model.check_model()))\n",
    "\n",
    "## Simulate values from the DAG\n",
    "def simulate_from_DAG(model, nsamps = 25, set_seed = 234):\n",
    "    nr.seed(set_seed)\n",
    "    simulation = BayesianModelSampling(model)\n",
    "    return(simulation.forward_sample(size = nsamps, return_type='dataframe'))\n",
    "\n",
    "\n",
    "nsamps = 25\n",
    "samples_25 = simulate_from_DAG(murder_model, nsamps = nsamps)\n",
    "samples_25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Parameter Estimation\n",
    "\n",
    "With the dataset generated you will now estimate the parameters of the graphical model using both maximum likelihood and Bayesian methods. \n",
    "\n",
    "As a first step execute the code in the cell below to load the packages you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "from pgmpy.estimators import HillClimbSearch, BicScore, K2Score, StructureScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create and execute the code in the cell below to estimate and display the parameters of the CPDs using the **maximum likelihood method** from the simulated graphy data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results and answer the following questions:\n",
    "1. How many parameters are there in the CPD tables?\n",
    "2. Keeping in mind that the probability of each column in a CPT must add to 1, how many free parameters must be fit for this model. \n",
    "3. Given the number of parameters, and the sample size of 25 cases, is this MLE problem under-determined and why? \n",
    "4. Notice the number of 0.0 and 1.0 parameter values. Is this evidence of an under-fit model, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1:      \n",
    "ANS 2:        \n",
    "ANS 3:      \n",
    "ANS 4:     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will estimate the CPD parameters using a **Bayesian estimator**. For this first estimate use the following moderately weak and uniform prior distributions (pseudo counts):\n",
    "\n",
    "- C: [3,3]\n",
    "- B: [3,3]\n",
    "- W: [[3,3,3,3], [3,3,3,3]]\n",
    "- MO: [[3,3,3,3], [3,3,3,3]]\n",
    "- M: [[2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2], [2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2]]\n",
    "\n",
    "In the cell below create and execute the code to perform Bayes estimation and display the CPD parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus your attention on the M and W CPDs. In terms of extreme values, how does the table computed with the Bayesian method compare to the table computed with MLE? Is this behavior evidence of the regularization property of the Bayesian estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1:       \n",
    "ANS 2:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next verify that the independencies of all the variables in your model are correct using the `local_independencies` method. Create and execute the code in the cell below to display the independencies in the CPD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Is your graph an I-map of the factorized distribution and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to perform inference on your model. Use the belief propagation method to query the M. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this resulting marginal distribution to the marginal distribution you obtained for the same query in the previous homework using the CDP tables provided. How do these distribution differ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will estimate the CPD parameters using the Bayesian estimator with a moderately weak but biased prior distribution. Such a prior distribution can be constructed from some combination of data from previous murder cases and the opinions of several investigators (experts). For this first estimate use the following prior distributions (pseudo counts):\n",
    "\n",
    "- C: [[8], [2]]\n",
    "- B: [[2],[8]]\n",
    "- W: [[2,4,2,3], [4,2,4,3]]\n",
    "- MO: [[3,2,4,3], [3,4,2,3]]\n",
    "- M: [[1,1,1,1,4,4,4,4,1,1,1,1,2,2,2,2], [1,1,1,1,1,1,1,1,4,4,4,4,2,2,2,2], [4,4,4,4,4,1,1,1,1,1,1,1,1,1,1,1]]\n",
    "\n",
    "In the cell below create and execute the code to perform Bayes estimation and display the CPD parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the parameters tables computed with the biased prior to those estimated with a uniform prior. How are these different, and is this expected given the change in prior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, how much does the prior matter in terms of inference? Use the belief propagation method to query the M variable and display the results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this marginal distribution to the one obtained with the a uniform prior. Would you say these differences are significant, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps more data will improve the estimation of the model parameters, particularly for the maximum likelihood method. In the cell below compute a new data set with 250 cases. Use a random seed value of 5678. Be sure to give your new data frame a different name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the model parameters using the 250 sample dataset and the **maximum likelihood estimator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these results to the MLE results you computed with 25 data cases. Are their fewer extreme values? But, does the presence of extreme values still indicate the model is under-fit despite an order of magnitude increase in the number of data cases? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1:      \n",
    "ANS 2:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will compare the MLE values to those produced by the **Bayesian estimator** using the same uniform prior as the first Bayes estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of evidence of under-fitting, such as repeated parameter values, how does these estimates compare to the Bayes estimates using 25 cases? Also, are probability tables for the butler and the cook closer to the original values from DAG model used for the simulation, when compare to the parameters computed with the Bayes estimator from 25 cases? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1:    \n",
    "ANS 2:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Estimation of Parameters\n",
    "\n",
    "To gain a feel for how a prior distribution changes the parameter estimates you will perform random sampling of data from the DAG model and estimate a model parameter. As a first step, write a function(s) that random samples a dataset and then estimates the parameter, $\\theta$. Your function(s) should do the following:\n",
    "\n",
    "1. Use the DAG model you imported for the simulation creating each dataset realization. \n",
    "2. Arguments should include the $\\alpha$ and $\\beta$ prior pseudo counts.\n",
    "3. The parameter, $\\theta$ is estimated for the butler, B, table. \n",
    "4. The number of samples per realized dataset is 25. \n",
    "5. Compute 1,000 estimates of $\\theta$, using 1,000 independent sample datasets.\n",
    "6. Use an initial random seed of 345, and increase your seed value by 100 for each realization.\n",
    "7. Return an array-like data structure containing your 1,000 parameter estimates. \n",
    "\n",
    "Create the code in the cell below. Then execute your code for a **maximum likelihood estimate** of the 1,000 values of theta by setting $\\alpha$ and $\\beta$ both to 0, and save the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to visualize the results as a histogram. Create a function to plot a histogram with of your parameter estimates using 50 bins and with x-axis limits of (0.2,0.9). Make sure to label your axes. Then, plot the histogram and examine the results. \n",
    "\n",
    "> **Note:** Since the DAG has a limited number of discrete valued notes, expect the histogram to have a number of discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the dispersion of the parameter estimates and the most likely value (mode). Given that the parameter, $\\theta$, must be in the range $0.0 \\le \\theta \\le 1.0$, would you say there is significant dispersion in these estimates, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, simulate a new realization of the 1,000 datasets, estimating the parameters, $\\theta$ using a prior with pseudo counts, alpha = 6, beta = 4. Then, plot the histogram to compare with the previous results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How has adding this prior changed the characteristics of the distribution of the parameter, $\\theta$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you will explore the learning properties of the Bayes estimator when very little data is available. You will compute realizations of datasets with just 5 samples and plot the histogram of the parameter estimates. Continue using a prior with pseudo counts, alpha = 6, beta = 4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the resulting histogram. The result has fewer discrete values that the histogram computed using a sample size of 25. But, are the dispersion and mode of these two distributions nearly the same and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you will investigate the effect of a strong prior. A strong prior arises in cases where there is considerable experience with the problem. In such cases, the new observations only incrementally change the parameter estimates. \n",
    "\n",
    "Simulate a new realization of datasets with 25 samples each, estimating the parameters, $\\theta$ using a prior with pseudo counts, alpha = 16, beta = 24. Then, plot the histogram to compare with the previous results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these results to the those obtained using the same prior with 25 samples per realization. What are the key differences between these distributions of the parameters, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2, Learning Structure\n",
    "\n",
    "Now you will explore how well the structure of the graph can be estimated. **Keep in mind that the graph used for the simulation is not a tree**. Answer the questions based on the results you find. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataset simulated, you will now try estimating the model structure. Use the hill climb search algorithm with the BIC scoring function to estimate the model structure, using the dataset with 250 samples. Set a `numpy.random.seed` of 5566, before computing the model. Create and execute the code in the cell below to estimate the model structure and display the identified edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(5566) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these edges. How does this model compare to the model used to simulate the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this structure fit? To answer this question you will need to compare the BIC score of the graph used for the simulation with the BIC score of the estimated structure. You must create a baseline DAG structure and compare the BIC score to the score of the estimated model. \n",
    "\n",
    "Notice that in practice, you will never know the true graph structure. Else, why estimate it? In such cases, the best you can do is test several models and select the one with the lowest BIC that also honors any constraints known from expert opinion. \n",
    "\n",
    "In the cell below create the code to compute and display the BIC score of both the graph used for the simulation and the estimated structure, using the 250 sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these BIC scores different and what does this mean in terms of how good the estimated model is? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will apply the K2 score method to the 250 case dataset. In the cell below, create the code to use the hill climbing search with the K2 score to estimate and display the model structure. Set a `numpy.random.seed` of 6565, before computing the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(6565)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this graph structure any different from the one obtained with the BIC score and what does this mean in terms of the independency structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compare the K2 score for the baseline DAG model with the estimated model using the 250 case dataset. In the cell below create and execute the code to compute and display these scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these K2 scores different and what does this indicate about the estimated model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below create and execute the code to display the independencies of the graph structure you have found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that these local independencies have some problematic characteristics. What statement can you make about these problems for the murderer variable, M?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps, a larger dataset will yield better DAGs? In the cell below, compute a dataset with 25,000 samples using the DAG model. Use a random seed of 9898. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the larger dataset available, you can now determine if using 2 orders of magnitude more data improves the model structure estimates. In the cell below, use the hill climb search algorithm with the BIC scoring function to estimate the model structure. Set a `numpy.random.seed` of 4567, before computing the model. Make sure you give you model a unique name so you can make comparisons latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(4567)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the 25,000 sample data set with the hill climb search algorithm using the K2 scoring function to estimate the model structure. Set a `numpy.random.seed` of 765, before computing the model. Make sure you give you model a unique name so you can make comparisons latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr.seed(765)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two scoring methods have arrived at different models, even when a larger dataset is used.  What are some key differences in these models and with the original models? **Hint:** Look at the numbers of directed edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The K2 score models have been created using a Dirichlet uniform prior, starting with a completely unconnected model. See the [pgmpy documentation for more details](http://pgmpy.org/estimators.html).   \n",
    "\n",
    "The addition of a prior in the form of an initial DAG model might make a difference. In the cell below a simple initial model is defined. You can specify an initial model using the `start` argument to the `estimate` method. \n",
    "\n",
    "Using the 25,000 case dataset and the initial model, use the K2 score to find a model structure. Set a `numpy.random.seed` of 543, before computing the model. Make sure you give you model a unique name so you can make comparisons latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the use of the prior or initial model changed the result? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compare the BIC and K2 scores of the three models you created with the K2 and BIC score methods on the 25,000 case dataset. In the cell below create and execute the code to compute and display these 6 scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine these results. Do the results indicate any one model is substantially better than the others? Does this outcome help explain the ambiguity you have seen in estimating model structure, and why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1:   \n",
    "ANS 2:    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, create and execute the code in the cell below, to print the local independencies of the models estimated using the K2 and BIC score methods on the 25,000 case dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the local indepenencies different? Which structure makes more sense when compared to the original DAG used for the simulation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS 1:     \n",
    "ANS 2:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
